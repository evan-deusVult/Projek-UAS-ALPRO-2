{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBC Prediction using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaldir = \"E:\\\\Download\\\\TB_Chest_Radiography_Database\\\\Normal\"\n",
    "tbdir = \"E:\\\\Download\\\\TB_Chest_Radiography_Database\\\\Tuberculosis\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "imagesize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in os.listdir(normaldir):\n",
    "    imagedir = os.path.join(normaldir,x)\n",
    "    image = cv.imread(imagedir,cv.IMREAD_GRAYSCALE)\n",
    "    image = cv.resize(image,(imagesize,imagesize))\n",
    "    images.append(image)\n",
    "    labels.append(0)\n",
    "\n",
    "for y in os.listdir(tbdir):\n",
    "    imagedir = os.path.join(tbdir,y)\n",
    "    image = cv.imread(imagedir,cv.IMREAD_GRAYSCALE)\n",
    "    image = cv.resize(image,(imagesize,imagesize))\n",
    "    images.append(image)\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "imagetrain, imagetest, labeltrain, labeltest = train_test_split(images,labels,test_size=0.3,random_state=42)\n",
    "imagetrain = (imagetrain.astype('float32'))/255\n",
    "imagetest = (imagetest.astype('float32'))/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4914, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "imagetrain = imagetrain.reshape(2940, (imagesize*imagesize))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "imagetrain, labeltrain = smote.fit_resample(imagetrain, labeltrain)\n",
    "\n",
    "\n",
    "imagetrain = imagetrain.reshape(-1, imagesize, imagesize, 1)\n",
    "print(imagetrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([2457, 2457], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(labeltrain,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential(\n",
    "    [\n",
    "    keras.Input(shape=(imagesize, imagesize, 1)),\n",
    "    \n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    \n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    loss='binary_crossentropy',\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "308/308 - 84s - loss: 0.2517 - accuracy: 0.8966 - lr: 0.0010 - 84s/epoch - 274ms/step\n",
      "Epoch 2/10\n",
      "308/308 - 89s - loss: 0.1103 - accuracy: 0.9611 - lr: 0.0010 - 89s/epoch - 289ms/step\n",
      "Epoch 3/10\n",
      "308/308 - 85s - loss: 0.0917 - accuracy: 0.9685 - lr: 0.0010 - 85s/epoch - 278ms/step\n",
      "Epoch 4/10\n",
      "308/308 - 81s - loss: 0.0452 - accuracy: 0.9856 - lr: 0.0010 - 81s/epoch - 263ms/step\n",
      "Epoch 5/10\n",
      "308/308 - 81s - loss: 0.0305 - accuracy: 0.9896 - lr: 0.0010 - 81s/epoch - 264ms/step\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "308/308 - 81s - loss: 0.0351 - accuracy: 0.9886 - lr: 0.0010 - 81s/epoch - 264ms/step\n",
      "Epoch 7/10\n",
      "308/308 - 83s - loss: 0.0150 - accuracy: 0.9951 - lr: 1.0000e-04 - 83s/epoch - 268ms/step\n",
      "Epoch 8/10\n",
      "308/308 - 81s - loss: 0.0107 - accuracy: 0.9965 - lr: 1.0000e-04 - 81s/epoch - 263ms/step\n",
      "Epoch 9/10\n",
      "308/308 - 82s - loss: 0.0080 - accuracy: 0.9972 - lr: 1.0000e-04 - 82s/epoch - 266ms/step\n",
      "Epoch 10/10\n",
      "308/308 - 79s - loss: 0.0076 - accuracy: 0.9976 - lr: 1.0000e-04 - 79s/epoch - 255ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cf4245e530>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='accuracy',factor=0.1,patience=1,min_lr=0.00001,verbose=1)\n",
    "\n",
    "cnn.fit(imagetrain,labeltrain,batch_size=16,epochs=10,verbose=2,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING DATA\n",
      "40/40 - 6s - loss: 0.1256 - accuracy: 0.9738 - 6s/epoch - 143ms/step\n",
      "ADVANCED TESTING METRICS : \n",
      "40/40 [==============================] - 5s 131ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1043\n",
      "           1       0.92      0.93      0.92       217\n",
      "\n",
      "    accuracy                           0.97      1260\n",
      "   macro avg       0.95      0.96      0.95      1260\n",
      "weighted avg       0.97      0.97      0.97      1260\n",
      "\n",
      "[[1025   18]\n",
      " [  15  202]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING DATA\")\n",
    "cnn.evaluate(imagetest,labeltest,batch_size=32,verbose=2)\n",
    "\n",
    "print(\"ADVANCED TESTING METRICS : \")\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "predictions = cnn.predict(imagetest,batch_size=32)\n",
    "predicted_labels = (predictions > 0.5).astype('int32')\n",
    "print(classification_report(labeltest,predicted_labels))\n",
    "print(confusion_matrix(labeltest,predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('hasil_model_cnn.pkl','wb') as file:\n",
    "    #pickle.dump(cnn,file)\n",
    "#print('model berhasil disimpan ke file ','hasil_model_cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil disimpan ke file \"hasil_model_cnn.h5\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI_PC\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "cnn.save('hasil_model_cnn_(2.13.1).h5')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
